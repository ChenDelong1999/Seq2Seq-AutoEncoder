{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(0)\n",
    "import os\n",
    "from scipy.ndimage import label\n",
    "import time\n",
    "import torch\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from segmenter import Segmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualized_masks(masks, image):\n",
    "    canvas = np.ones_like(image) * 255\n",
    "    masks = sorted(masks, key=lambda x: x['area'], reverse=True)\n",
    "    for mask in masks:\n",
    "        average_color = np.mean(image[mask['segmentation'] == 1], axis=0)\n",
    "        canvas[mask['segmentation'] == 1] = average_color\n",
    "\n",
    "        # visualize segment boundary\n",
    "        contours, _ = cv2.findContours(mask['segmentation'].astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cv2.drawContours(canvas, contours, -1, (200, 200, 200), 1)\n",
    "\n",
    "    return canvas\n",
    "\n",
    "\n",
    "def get_masked_area(masks):\n",
    "    masked_area = None\n",
    "    for mask in masks:\n",
    "        if masked_area is None:\n",
    "            masked_area = mask['segmentation'].astype(np.uint8)\n",
    "        else:\n",
    "            masked_area[mask['segmentation']] += 1\n",
    "\n",
    "    non_masked_area = (masked_area == 0).astype(np.uint8)\n",
    "    return masked_area, non_masked_area\n",
    "\n",
    "\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'\n",
    "\n",
    "img_dir = '/home/dchenbs/workspace/datasets/coco2017/images/val2017'\n",
    "num_test_images = 8\n",
    "visualize = True\n",
    "\n",
    "checkpoints = [\n",
    "    '/home/dchenbs/workspace/Seq2Seq-AutoEncoder/RepViT/sam/weights/repvit_sam.pt',\n",
    "    '/home/dchenbs/workspace/cache/mobile_sam.pt',\n",
    "    \"/home/dchenbs/workspace/cache/sam_vit_h_4b8939.pth\",\n",
    "    \"/home/dchenbs/workspace/cache/sam_vit_l_0b3195.pth\",\n",
    "    \"/home/dchenbs/workspace/cache/sam_vit_b_01ec64.pth\",\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "(Default)\n",
    "crop_n_layers=0,\n",
    "crop_n_points_downscale_factor=1,\n",
    "\n",
    "    RepVIT SAM\n",
    "    100%|██████████| 100/100 [02:16<00:00,  1.36s/it]\n",
    "    Mobile SAM\n",
    "    100%|██████████| 100/100 [02:05<00:00,  1.25s/it]\n",
    "    SAM vit_h\n",
    "    100%|██████████| 100/100 [03:03<00:00,  1.84s/it]\n",
    "    SAM vit_l\n",
    "    100%|██████████| 100/100 [02:43<00:00,  1.64s/it]\n",
    "    SAM vit_b\n",
    "    100%|██████████| 100/100 [01:55<00:00,  1.16s/it]\n",
    "\n",
    "------------------------\n",
    "crop_n_layers=1,\n",
    "crop_n_points_downscale_factor=2,\n",
    "\n",
    "    RepVIT SAM\n",
    "    100%|██████████| 100/100 [04:15<00:00,  2.55s/it]\n",
    "    Mobile SAM\n",
    "    100%|██████████| 100/100 [04:01<00:00,  2.41s/it]\n",
    "    SAM vit_h\n",
    "    100%|██████████| 100/100 [07:46<00:00,  4.67s/it]\n",
    "    SAM vit_l\n",
    "    100%|██████████| 100/100 [06:08<00:00,  3.69s/it]\n",
    "    SAM vit_b\n",
    "    100%|██████████| 100/100 [04:13<00:00,  2.54s/it]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "for checkpoint in checkpoints:\n",
    "    # Default\n",
    "    segmenter = Segmenter(\n",
    "        checkpoint,\n",
    "        # points_per_side = 32,\n",
    "        # points_per_batch = 64,\n",
    "        # pred_iou_thresh = 0.88,\n",
    "        # stability_score_thresh = 0.95,\n",
    "        # stability_score_offset = 1.0,\n",
    "        # box_nms_thresh = 0.7,\n",
    "        # crop_n_layers = 0,\n",
    "        # crop_nms_thresh = 0.7,\n",
    "        # crop_overlap_ratio = 512 / 1500,\n",
    "        # crop_n_points_downscale_factor = 1,\n",
    "        # min_mask_region_area = 0,\n",
    "    )\n",
    "    \n",
    "    # # Finer but longer\n",
    "    # segmenter = Segmenter(\n",
    "    #     checkpoint,\n",
    "    #     points_per_side=32,\n",
    "    #     pred_iou_thresh=0.86,\n",
    "    #     stability_score_thresh=0.92,\n",
    "    #     crop_n_layers=1,\n",
    "    #     crop_n_points_downscale_factor=2,\n",
    "    #     )\n",
    "\n",
    "    for i in tqdm.tqdm(range(num_test_images)):\n",
    "        img_path = os.path.join(img_dir, random.choice(os.listdir(img_dir)))\n",
    "        image = np.array(Image.open(img_path).convert('RGB'))\n",
    "        masks = segmenter(image)\n",
    "\n",
    "        if visualize:\n",
    "            plt.figure(figsize=(20, 8))\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(image)\n",
    "            plt.axis('off')\n",
    "\n",
    "            canvas = visualized_masks(masks, image)\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(canvas)\n",
    "            plt.axis('off')\n",
    "\n",
    "            masked_area, non_masked_area = get_masked_area(masks)\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(masked_area*int(255/max(masked_area.flatten())))\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seq2seq-ae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
