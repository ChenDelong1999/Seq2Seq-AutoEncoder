{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(0)\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'\n",
    "from scipy.ndimage import label\n",
    "import time\n",
    "import torch\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "import pprint\n",
    "from segmentation import Segmenter, visualized_masks, get_masked_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_images = 100\n",
    "visualize = False\n",
    "\n",
    "img_dir = '/home/dchenbs/workspace/datasets/coco2017/images/val2017'\n",
    "image_paths = []\n",
    "for i in range(num_test_images):\n",
    "    img_path = os.path.join(img_dir, random.choice(os.listdir(img_dir)))\n",
    "    image_paths.append(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:51<00:00,  1.96it/s]\n"
     ]
    }
   ],
   "source": [
    "import json, requests\n",
    "import pickle\n",
    "import base64\n",
    "\n",
    "port = '5000'\n",
    "\n",
    "url = f'http://0.0.0.0:{port}/segment_provider'\n",
    "\n",
    "for image_path in tqdm.tqdm(image_paths):\n",
    "    content_lst = {\n",
    "        'post_processing': True, \n",
    "        'img_path': image_path\n",
    "    }\n",
    "    d = {\"content_lst\": content_lst, 'typ': 'None'}\n",
    "    d = json.dumps(d).encode('utf8')\n",
    "    r = requests.post(url, data=d)\n",
    "    js = json.loads(r.text)\n",
    "\n",
    "    masks_bytes = base64.b64decode(js['result']['response'])\n",
    "    masks = pickle.loads(masks_bytes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \n",
    "    # ('sam', '/home/dchenbs/workspace/cache/sam_weights/sam/sam_vit_h_4b8939.pth'), \n",
    "    #     # 6.972 GB, 1.83 s/image\n",
    "\n",
    "    # ('sam', '/home/dchenbs/workspace/cache/sam_weights/sam/sam_vit_l_0b3195.pth'), \n",
    "    #     # 5.516 GB, 1.59 s/image\n",
    "\n",
    "    # ('sam', '/home/dchenbs/workspace/cache/sam_weights/sam/sam_vit_b_01ec64.pth'), \n",
    "    #     # 4.572 GB, 1.12 s/image\n",
    "    \n",
    "    # ('mobile_sam', '/home/dchenbs/workspace/cache/sam_weights/mobile_sam.pt'),\n",
    "    #     # 4.376 GB, 1.24 s/image\n",
    "    \n",
    "    ('mobile_sam_v2', '/home/dchenbs/workspace/cache/sam_weights/mobile_sam_v2/l2.pt'),\n",
    "    #     # 11.982 GB, 0.20 s/image\n",
    "    \n",
    "    # ('repvit_sam', '/home/dchenbs/workspace/Seq2Seq-AutoEncoder/RepViT/sam/weights/repvit_sam.pt'), \n",
    "    #     # 4.722 GB, 1.35 s/image\n",
    "       \n",
    "    # --- somehow broken\n",
    "\n",
    "    # ('fast_sam', '/home/dchenbs/workspace/cache/sam_weights/fast_sam/FastSAM-s.pt'),  \n",
    "    #     # 1.326 GB, 0.34 s/image\n",
    "\n",
    "    # ('fast_sam', '/home/dchenbs/workspace/cache/sam_weights/fast_sam/FastSAM.pt'), \n",
    "    #     # 1.946 GB, 0.24 s/image\n",
    "]\n",
    "\n",
    "results = []\n",
    "for model_name, checkpoint in models:\n",
    "    print(f'Running [{model_name.upper()}]: {checkpoint.split(\"/\")[-1]}')\n",
    "\n",
    "    segmenter = None\n",
    "    torch.cuda.empty_cache()\n",
    "    segmenter = Segmenter(model_name, checkpoint)\n",
    "    \n",
    "    start = time.time()\n",
    "    for img_path in tqdm.tqdm(image_paths):\n",
    "        image = np.array(Image.open(img_path).convert('RGB'))\n",
    "        masks = segmenter(img_path, post_processing=True)\n",
    "        \n",
    "        if visualize:\n",
    "            plt.figure(figsize=(20, 8))\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(image)\n",
    "            plt.axis('off')\n",
    "\n",
    "            canvas = visualized_masks(masks, image)\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(canvas)\n",
    "            plt.axis('off')\n",
    "\n",
    "            masked_area, non_masked_area = get_masked_area(masks)\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(masked_area*int(255/max(masked_area.flatten())))\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    result = {\n",
    "        'model_name': model_name,\n",
    "        'checkpoint': checkpoint,\n",
    "        'seconds_per_image': (time.time()-start)/num_test_images,\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "pprint.pprint(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seq2seq-ae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
