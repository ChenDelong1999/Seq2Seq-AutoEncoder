{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
    "import random\n",
    "random.seed(0)\n",
    "import os\n",
    "from scipy.ndimage import label\n",
    "import time\n",
    "import torch\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "\n",
    "class Segmenter():\n",
    "\n",
    "    def __init__(self, sam_ckpt):\n",
    "        \n",
    "        model_type = sam_ckpt.split('/')[-1][4:9]\n",
    "        print(f'Loading SAM model {model_type} from {sam_ckpt}')\n",
    "\n",
    "        sam = sam_model_registry[model_type](checkpoint=sam_ckpt).to(\"cuda\").eval()\n",
    "\n",
    "        # generator = SamAutomaticMaskGenerator(sam)\n",
    "        self.generator = SamAutomaticMaskGenerator(\n",
    "            sam,\n",
    "            points_per_side=32,\n",
    "            pred_iou_thresh=0.86,\n",
    "            stability_score_thresh=0.92,\n",
    "            crop_n_layers=1,\n",
    "            crop_n_points_downscale_factor=2,\n",
    "            # min_mask_region_area=100,  # Requires open-cv to run post-processing\n",
    "            )\n",
    "        \n",
    "    def __call__(self, image):        \n",
    "        masks = self.generator.generate(image)\n",
    "        masks = self.post_processing_masks(masks, image)\n",
    "        return masks\n",
    "\n",
    "    def expand_mask_blur(self, mask, kernel):\n",
    "        mask = mask.copy()\n",
    "        mask['segmentation'] = mask['segmentation'].astype(np.uint8)\n",
    "        blurred_mask = cv2.filter2D(mask['segmentation'],-1,kernel)\n",
    "        expanded_mask = (blurred_mask > 0).astype(bool)\n",
    "        return expanded_mask\n",
    "\n",
    "\n",
    "    def post_processing_masks(self, masks, image):\n",
    "\n",
    "        kernel_size = int(min(image.shape[:2]) * 0.015) // 2 * 2 + 1\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(kernel_size,kernel_size))\n",
    "\n",
    "        masked_area = None\n",
    "        post_processed_masks = []\n",
    "        for mask in masks:\n",
    "            expanded_mask = self.expand_mask_blur(mask, kernel)\n",
    "            post_processed_masks.append({\n",
    "                'segmentation': expanded_mask.astype(bool),\n",
    "                'area': expanded_mask.sum(),\n",
    "                'bbox': cv2.boundingRect(expanded_mask.astype(np.uint8)),\n",
    "            })\n",
    "            if masked_area is None:\n",
    "                masked_area = expanded_mask.astype(np.uint8)\n",
    "            else:\n",
    "                masked_area[expanded_mask] += 1\n",
    "\n",
    "        non_masked_area = masked_area == 0\n",
    "        labeled_mask, num_labels = label(non_masked_area)\n",
    "        \n",
    "        for i in range(1, num_labels + 1):\n",
    "            post_processed_masks.append({\n",
    "                'segmentation': labeled_mask == i,\n",
    "                'area': (labeled_mask == i).sum(),\n",
    "                'bbox': cv2.boundingRect((labeled_mask == i).astype(np.uint8)),\n",
    "            })\n",
    "        return post_processed_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /home/dchenbs/workspace/cache/sam_vit_h_4b8939.pth\n",
      "Loading SAM model vit_h from /home/dchenbs/workspace/cache/sam_vit_h_4b8939.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [07:46<00:00,  4.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /home/dchenbs/workspace/cache/sam_vit_l_0b3195.pth\n",
      "Loading SAM model vit_l from /home/dchenbs/workspace/cache/sam_vit_l_0b3195.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [06:08<00:00,  3.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /home/dchenbs/workspace/cache/sam_vit_b_01ec64.pth\n",
      "Loading SAM model vit_b from /home/dchenbs/workspace/cache/sam_vit_b_01ec64.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:13<00:00,  2.54s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def visualized_masks(masks, image):\n",
    "    canvas = np.ones_like(image) * 255\n",
    "    masks = sorted(masks, key=lambda x: x['area'], reverse=True)\n",
    "    for mask in masks:\n",
    "        average_color = np.mean(image[mask['segmentation'] == 1], axis=0)\n",
    "        canvas[mask['segmentation'] == 1] = average_color\n",
    "\n",
    "        # visualize segment boundary\n",
    "        contours, _ = cv2.findContours(mask['segmentation'].astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cv2.drawContours(canvas, contours, -1, (200, 200, 200), 1)\n",
    "\n",
    "    return canvas\n",
    "\n",
    "\n",
    "def get_masked_area(masks):\n",
    "    masked_area = None\n",
    "    for mask in masks:\n",
    "        if masked_area is None:\n",
    "            masked_area = mask['segmentation'].astype(np.uint8)\n",
    "        else:\n",
    "            masked_area[mask['segmentation']] += 1\n",
    "\n",
    "    non_masked_area = (masked_area == 0).astype(np.uint8)\n",
    "    return masked_area, non_masked_area\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "img_dir = '/home/dchenbs/workspace/datasets/coco2017/images/val2017'\n",
    "num_test_images = 100\n",
    "\n",
    "checkpoints = [\n",
    "    \"/home/dchenbs/workspace/cache/sam_vit_h_4b8939.pth\",\n",
    "    \"/home/dchenbs/workspace/cache/sam_vit_l_0b3195.pth\",\n",
    "    \"/home/dchenbs/workspace/cache/sam_vit_b_01ec64.pth\",\n",
    "]\n",
    "\"\"\"\n",
    "Loading SAM model vit_h from /home/dchenbs/workspace/cache/sam_vit_h_4b8939.pth\n",
    "100%|██████████| 100/100 [07:46<00:00,  4.67s/it]\n",
    "Loading SAM model vit_l from /home/dchenbs/workspace/cache/sam_vit_l_0b3195.pth\n",
    "100%|██████████| 100/100 [06:08<00:00,  3.69s/it]\n",
    "Loading SAM model vit_b from /home/dchenbs/workspace/cache/sam_vit_b_01ec64.pth\n",
    "100%|██████████| 100/100 [04:13<00:00,  2.54s/it]\n",
    "\"\"\"\n",
    "\n",
    "# checkpoint=\"/home/dchenbs/workspace/cache/sam_vit_b_01ec64.pth\"\n",
    "for checkpoint in checkpoints:\n",
    "    segmenter = Segmenter(checkpoint)\n",
    "\n",
    "    for i in tqdm.tqdm(range(num_test_images)):\n",
    "        img_path = os.path.join(img_dir, random.choice(os.listdir(img_dir)))\n",
    "        image = np.array(Image.open(img_path).convert('RGB'))\n",
    "        masks = segmenter(image)\n",
    "\n",
    "        # plt.figure(figsize=(20, 4))\n",
    "        # plt.subplot(1, 5, 1)\n",
    "        # plt.imshow(image)\n",
    "        # plt.axis('off')\n",
    "\n",
    "        # canvas = visualized_masks(masks, image)\n",
    "        # plt.subplot(1, 5, 3)\n",
    "        # plt.imshow(canvas)\n",
    "        # plt.axis('off')\n",
    "\n",
    "        # masked_area, non_masked_area = get_masked_area(masks)\n",
    "        # plt.subplot(1, 5, 4)\n",
    "        # plt.imshow(masked_area*int(255/max(masked_area.flatten())))\n",
    "        # plt.axis('off')\n",
    "\n",
    "        # plt.tight_layout()\n",
    "        # plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seq2seq-ae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
